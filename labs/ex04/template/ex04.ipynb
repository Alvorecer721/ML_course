{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from test_utils import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation and Bias-Variance decomposition\n",
    "## Cross-Validation\n",
    "Implementing 4-fold cross-validation below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import load_data\n",
    "\n",
    "# load dataset\n",
    "x, y = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "\n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "\n",
    "    >>> build_k_indices(np.array([1., 2., 3., 4.]), 2, 1)\n",
    "    array([[3, 2],\n",
    "           [0, 1]])\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval : (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `build_k_indices` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "test(build_k_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the following cross_validation( ) function you need to implement, you can help yourselves of the build_poly( ) and ridge_regression( ) functions that you implemented in lab 3. Copy paste the code in the build_polynomial.py and ridge_regression.py files, they should pass the two following tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Your `build_poly` passes some basic tests.\n",
      "✅ Your `ridge_regression` passes some basic tests.\n"
     ]
    }
   ],
   "source": [
    "from costs import compute_mse\n",
    "from ridge_regression import ridge_regression\n",
    "from build_polynomial import build_poly\n",
    "\n",
    "\n",
    "test(build_poly)\n",
    "test(ridge_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression for a fold corresponding to k_indices\n",
    "\n",
    "    Args:\n",
    "        y:          shape=(N,)\n",
    "        x:          shape=(N,)\n",
    "        k_indices:  2D array returned by build_k_indices()\n",
    "        k:          scalar, the k-th fold (N.B.: not to confused with k_fold which is the fold nums)\n",
    "        lambda_:    scalar, cf. ridge_regression()\n",
    "        degree:     scalar, cf. build_poly()\n",
    "\n",
    "    Returns:\n",
    "        train and test root mean square errors rmse = sqrt(2 mse)\n",
    "\n",
    "    >>> cross_validation(np.array([1.,2.,3.,4.]), np.array([6.,7.,8.,9.]), np.array([[3,2], [0,1]]), 1, 2, 3)\n",
    "    (0.019866645527597114, 0.33555914361295175)\n",
    "    \"\"\"\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # get k'th subgroup in test, others in train: TODO\n",
    "    valid_indices = k_indices[k]\n",
    "    train_indices = k_indices[np.delete(range(len(k_indices)), k, axis=0)].flatten()\n",
    "    # ***************************************************\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # form data with polynomial degree: TODO\n",
    "    train_x = build_poly(x[train_indices], degree)\n",
    "    valid_x = build_poly(x[valid_indices], degree)\n",
    "    # ***************************************************\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # ridge regression: TODO\n",
    "    w = ridge_regression(y[train_indices], train_x, lambda_)\n",
    "    # ***************************************************\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # calculate the loss for train and test data: TODO\n",
    "    loss_tr = np.sqrt(2 * compute_mse(y[train_indices], train_x, w))\n",
    "    loss_te = np.sqrt(2 * compute_mse(y[valid_indices], valid_x, w))\n",
    "    # ***************************************************\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ The are some issues with your implementation of `cross_validation`:\n",
      "**********************************************************************\n",
      "File \"__main__\", line 15, in cross_validation\n",
      "Failed example:\n",
      "    cross_validation(np.array([1.,2.,3.,4.]), np.array([6.,7.,8.,9.]), np.array([[3,2], [0,1]]), 1, 2, 3)\n",
      "Expected:\n",
      "    (0.019866645527597114, 0.33555914361295175)\n",
      "Got:\n",
      "    (0.019866645527598144, 0.3355591436129497)\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "# can lead to a numerical error if you use an older version than Python 3.9\n",
    "test(cross_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-10-13T09:35:27.253733Z",
     "start_time": "2023-10-13T09:35:23.317811Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor polynomial expansion up to degree \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m.f, the choice of lambda which leads to the best test rmse is \u001b[39m\u001b[38;5;132;01m%.5f\u001b[39;00m\u001b[38;5;124m with a test rmse of \u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;241m%\u001b[39m (degree, best_lambda, best_rmse)\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m best_lambda, best_rmse\n\u001b[0;32m---> 44\u001b[0m best_lambda, best_rmse \u001b[38;5;241m=\u001b[39m cross_validation_demo(\u001b[38;5;241m7\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m30\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "from plots import cross_validation_visualization\n",
    "\n",
    "\n",
    "def cross_validation_demo(degree, k_fold, lambdas):\n",
    "    \"\"\"cross validation over regularisation parameter lambda.\n",
    "\n",
    "    Args:\n",
    "        degree: integer, degree of the polynomial expansion\n",
    "        k_fold: integer, the number of folds\n",
    "        lambdas: shape = (p, ) where p is the number of values of lambda to test\n",
    "    Returns:\n",
    "        best_lambda : scalar, value of the best lambda\n",
    "        best_rmse : scalar, the associated root mean squared error for the best lambda\n",
    "    \"\"\"\n",
    "\n",
    "    seed = 12\n",
    "    degree = degree\n",
    "    k_fold = k_fold\n",
    "    lambdas = lambdas\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    rmse_tr = []\n",
    "    rmse_te = []\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation over lambdas: TODO\n",
    "    for lambda_ in lambdas:\n",
    "        rmse_tr.append(\n",
    "            np.mean(\n",
    "                [\n",
    "                    cross_validation(y, x, k_indices, k, lambda_, degree)[0]\n",
    "                    for k in range(k_fold)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        rmse_te.append(\n",
    "            np.mean(\n",
    "                [\n",
    "                    cross_validation(y, x, k_indices, k, lambda_, degree)[1]\n",
    "                    for k in range(k_fold)\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    # ***************************************************\n",
    "\n",
    "    best_lambda = lambdas[np.argmin(rmse_te)]\n",
    "    best_rmse = np.min(rmse_te)\n",
    "\n",
    "    cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    print(\n",
    "        \"For polynomial expansion up to degree %.f, the choice of lambda which leads to the best test rmse is %.5f with a test rmse of %.3f\"\n",
    "        % (degree, best_lambda, best_rmse)\n",
    "    )\n",
    "    return best_lambda, best_rmse\n",
    "\n",
    "\n",
    "best_lambda, best_rmse = cross_validation_demo(7, 4, np.logspace(-4, 0, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should look like this for seed = 12, degree = 7 and k_fold = 4:\n",
    "\n",
    "![alt text](cross_validation2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can play around with the number of folds and the degree of your polynomial expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For polynomial expansion up to degree 10, the choice of lambda which leads to the best test rmse is 0.00002 with a test rmse of 0.312\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "best_lambda, best_rmse = cross_validation_demo(10, 4, np.logspace(-10, -2, 30))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous task we did a grid search over several values of $\\lambda$ for a fixed degree. We can also perform a grid search amongst $\\lambda$ and degrees simultaneously:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_degree_selection(degrees, k_fold, lambdas, seed=1):\n",
    "    \"\"\"cross validation over regularisation parameter lambda and degree.\n",
    "\n",
    "    Args:\n",
    "        degrees: shape = (d,), where d is the number of degrees to test\n",
    "        k_fold: integer, the number of folds\n",
    "        lambdas: shape = (p, ) where p is the number of values of lambda to test\n",
    "    Returns:\n",
    "        best_degree : integer, value of the best degree\n",
    "        best_lambda : scalar, value of the best lambda\n",
    "        best_rmse : value of the rmse for the couple (best_degree, best_lambda)\n",
    "\n",
    "    >>> best_degree_selection(np.arange(2,11), 4, np.logspace(-4, 0, 30))\n",
    "    (7, 0.004520353656360241, 0.28957280566456634)\n",
    "    \"\"\"\n",
    "\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "\n",
    "    best_rmse = float(\"inf\")  # set to infinity initially so any error will be smaller\n",
    "    best_degree = None\n",
    "    best_lambda = None\n",
    "\n",
    "    # ***************************************************\n",
    "    # INSERT YOUR CODE HERE\n",
    "    # cross validation over degrees and lambdas: TODO\n",
    "    for lambda_ in lambdas:\n",
    "        for degree in degrees:\n",
    "            # calculate the mean rmse across all folds for the current lambda and degree\n",
    "            mean_rmse = np.mean(\n",
    "                [\n",
    "                    cross_validation(y, x, k_indices, k, lambda_, degree)[1]\n",
    "                    for k in range(k_fold)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            # update the best values if the current rmse is smaller than the best observed so far\n",
    "            if mean_rmse < best_rmse:\n",
    "                best_rmse = mean_rmse\n",
    "                best_degree = degree\n",
    "                best_lambda = lambda_\n",
    "    # ***************************************************\n",
    "\n",
    "    return best_degree, best_lambda, best_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ The are some issues with your implementation of `best_degree_selection`:\n",
      "**********************************************************************\n",
      "File \"__main__\", line 13, in best_degree_selection\n",
      "Failed example:\n",
      "    best_degree_selection(np.arange(2,11), 4, np.logspace(-4, 0, 30))\n",
      "Expected:\n",
      "    (7, 0.004520353656360241, 0.28957280566456634)\n",
      "Got:\n",
      "    (7, 0.004520353656360241, 0.2895728056621761)\n",
      "**********************************************************************\n",
      "The best rmse of 0.290 is obtained for a degree of 7 and a lambda of 0.00452.\n"
     ]
    }
   ],
   "source": [
    "# can lead to a numerical error if you use an older version than Python 3.9\n",
    "test(best_degree_selection)\n",
    "\n",
    "best_degree, best_lambda, best_rmse = best_degree_selection(\n",
    "    np.arange(2, 11), 4, np.logspace(-4, 0, 30)\n",
    ")\n",
    "print(\n",
    "    \"The best rmse of %.3f is obtained for a degree of %.f and a lambda of %.5f.\"\n",
    "    % (best_rmse, best_degree, best_lambda)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# true function we want to learn\n",
    "def f_star(x):\n",
    "    return x**3 - x**2 + 0.5\n",
    "\n",
    "\n",
    "# plotting function for f_star\n",
    "def plot_fstar(ax):\n",
    "    xvals = np.arange(-1, 1, 0.01)\n",
    "    ax.plot(xvals, f_star(xvals), linestyle=\"--\", color=\"k\", label=\"f_star\")\n",
    "    ax.set_ylim(-2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper plot function\n",
    "def plot_poly(x, y, weights, degree, ax, alpha=0.3):\n",
    "    xvals = np.arange(-1, 1, 0.01)\n",
    "    tx = build_poly(xvals, degree)\n",
    "    f = tx.dot(weights)\n",
    "    ax.plot(xvals, f, color=\"orange\", alpha=alpha)\n",
    "    ax.scatter(x, y, color=\"b\", alpha=alpha, s=10)\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    ax.set_title(\"Polynomial degree \" + str(degree))\n",
    "    ax.set_ylim(-1, 2)\n",
    "\n",
    "\n",
    "# helper plot function\n",
    "def plot_f(weights, degree, ax, label=None):\n",
    "    xvals = np.arange(-1, 1, 0.01)\n",
    "    tx = build_poly(xvals, degree)\n",
    "    f = tx.dot(weights)\n",
    "    ax.plot(xvals, f, color=\"black\", alpha=1, label=label)\n",
    "    ax.set_ylim(-1, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the following function: for 15 random datapoints, it finds the optimal fit (using the least square formula, with no regularisation λ) for a polynomial expansion of degree 1, 3 and 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from least_squares import least_squares\n",
    "\n",
    "\n",
    "def bias_variance_one_seed(sigma, degrees, seed):\n",
    "    \"\"\"One run of the optimal fit for 15 random points and different polynomial expansion degrees.\n",
    "\n",
    "    Args:\n",
    "        sigma: scalar, noise variance\n",
    "        degrees: shape = (3,), 3 different degrees to consider\n",
    "        seed: integer, random see\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "\n",
    "    # we will generate 15 random datapoints from the [-1, 1] uniform distribuion\n",
    "    num_data = 15\n",
    "    np.random.seed(seed)  # set random seed for reproducibility\n",
    "    xs = np.random.uniform(-1, 1, num_data)\n",
    "    # the outputs will be f_star(x) + some random gaussian noise of variance sigma**2\n",
    "    ys = f_star(xs) + sigma * np.random.randn(num_data)\n",
    "\n",
    "    fig, axs = plt.subplots(1, len(degrees), figsize=(20, 5))\n",
    "    for index_degree, degree in enumerate(degrees):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ***************************************************\n",
    "\n",
    "        plot_fstar(axs[index_degree])\n",
    "        axs[index_degree].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "bias_variance_one_seed(0.1, [1, 3, 6], seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should ressemble (for seed = 2) to this: \n",
    "![alt text](bias_variance_one_run.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to illustrate the bias variance tradeoff we will repeat many times the previous experiment but using a different random seed each time. We also plot (in plain black) the mean of all the orange functions obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bias_variance_demo(sigma, degrees):\n",
    "    \"\"\"Illustration of the bias-variance tradeoff.\n",
    "\n",
    "    Args:\n",
    "        sigma: scalar, noise variance\n",
    "        degrees: shape = (3,), 3 different degrees to consider\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    # define parameters\n",
    "    seeds = range(400)  # number of runs\n",
    "    num_data = 15\n",
    "\n",
    "    fig, axs = plt.subplots(1, len(degrees), figsize=(20, 5))\n",
    "    for index_degree, degree in enumerate(degrees):\n",
    "        # ***************************************************\n",
    "        # INSERT YOUR CODE HERE\n",
    "        # ***************************************************\n",
    "\n",
    "        plot_fstar(axs[index_degree])\n",
    "        axs[index_degree].legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "bias_variance_demo(0.1, [1, 3, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your output should ressemble to this: \n",
    "![alt text](bias_variance.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-Related",
   "language": "python",
   "name": "ml-related"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbdime-conflicts": {
   "local_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "ML-Related",
      "language": "python",
      "name": "ml-related"
     }
    },
    {
     "diff": [
      {
       "key": "version",
       "op": "add",
       "value": "3.9.12"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ],
   "remote_diff": [
    {
     "key": "kernelspec",
     "op": "add",
     "value": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     }
    },
    {
     "diff": [
      {
       "key": "version",
       "op": "add",
       "value": "3.10.9"
      }
     ],
     "key": "language_info",
     "op": "patch"
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
